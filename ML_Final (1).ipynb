{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used for reading the test data sets, I wanted to find the number of categorical columns so i selected the int data type columns and printed them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "train_df=p.read_csv(\"train_set.csv\")\n",
    "test_df=p.read_csv(\"test_set.csv\")\n",
    "print(\"Train df head\")\n",
    "print(train_df.head())\n",
    "print(train_df.select_dtypes(include=['int']).columns)\n",
    "print(train_df['X16'].mean)\n",
    "# Count the number of non-zero values in column x16\n",
    "non_zero_count = (train_df['X16'] != 0).sum()\n",
    "print(\"Number of non-zero values in x16:\", non_zero_count)\n",
    "unique_values = train_df['X16'].unique()\n",
    "print(\"Unique values in X16:\", unique_values)\n",
    "print(\"Test df head\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked columns separately which had integer values and had unique values between the range of 3 to 4 unique, i thought they were categorical and so i mean imputed the rest and mode imputed the integer ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Specify columns for different imputation strategies\n",
    "mean_impute_cols = [col for col in train_df.columns if col not in ['X4', 'X5', 'X6', 'X8', 'X10', 'X11', 'X16', 'Y']]\n",
    "mode_impute_cols = ['X4', 'X5', 'X6', 'X8', 'X10', 'X11', 'X16']\n",
    "\n",
    "# Mean impute selected columns\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "train_df[mean_impute_cols] = mean_imputer.fit_transform(train_df[mean_impute_cols])\n",
    "\n",
    "# Mode impute the remaining specified columns\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_df[mode_impute_cols] = mode_imputer.fit_transform(train_df[mode_impute_cols])\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks the correlation of columns using a correlation matrix and then filters out or drops the columns which had correlation greater than or equal to the set threshold, the columns which were dropped were appended in a list so that later on they can be dropped from the test data set too\n",
    "\n",
    "80% correlation was the optimal one, threshold set at above 80 or below 80 didnt work that well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Calculating Correlation and Reducing Features\n",
    "import pandas as pd\n",
    "import numpy as np  # Explicitly import numpy\n",
    "\n",
    "dropped_columns = []\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = train_df.corr().abs()\n",
    "\n",
    "# Set threshold for removing correlated features before it was 0.85\n",
    "correlation_threshold = 0.8\n",
    "\n",
    "# Select upper triangle of the correlation matrix\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Identify features to drop based on the correlation threshold\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > correlation_threshold)]\n",
    "\n",
    "# Store the names of dropped columns\n",
    "dropped_columns = to_drop.copy()\n",
    "\n",
    "# Drop the highly correlated features from the training set\n",
    "train_df_reduced = train_df.drop(columns=to_drop)\n",
    "\n",
    "# Redefine Features and Target with reduced features\n",
    "Features_reduced = train_df_reduced.drop(columns=['RecordId', 'Y'])\n",
    "Target = train_df_reduced['Y']\n",
    "\n",
    "# Print the reduced feature set\n",
    "print(f\"Features reduced from {train_df.shape[1]} to {train_df_reduced.shape[1]}\")\n",
    "print(Features_reduced.head())\n",
    "print(Features_reduced.shape)\n",
    "print(dropped_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below standardizes the training data set as minmax was not working well for the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Features = scaler.fit_transform(Features_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the estimators increase the accuracy gradually increases, I tried Gradient Boosting and before this Bagging as well, Ada performed well as i explored the base estimator a bit more for Ada. Setting the depth to less as well as the learning rate to lesser values increased the overall performance of the model. I tried giving important to positive or 1 class values by setting the class_weight to 'balanced' which did increase the recall of the model howevre at the cost of precision. The overall accuracy then stayed at 93%. \n",
    "\n",
    "I had to then change the approach and sadly focus on precision even though in health sets it is better to focus on recall as False Negatives can be extremely costly in health matters. So I gave utmost weightage to negative or 0 class which sigificantly increased the overall precision and the accuracy. What actually is happening is that because the amount of negative samples are significantly more in our data set, they are being correctly predicted because of the weightage and priority given to them thus increasing the overall accuracy however at the cost of positive sample predictions(recall) as they are less in number so the overall accuracy isnt being disturbed because of it\n",
    "\n",
    "There was always a trade off between recall and precision\n",
    "\n",
    "PCA(decreased accuracy) and Naive Bayes didnt work that well, it might have worked better on categorical data\n",
    "\n",
    "The test data set was also imputed, but by not scaling the test set it increased the accuracy of our predictions\n",
    "\n",
    "The code below was my best code till date at accuracy of 95.181%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Perform a 70/30 train-test split\n",
    "train_f, val_f, train_t, val_t = train_test_split(Features_reduced, Target, test_size=0.30, random_state=42)\n",
    "dt = DecisionTreeClassifier(max_depth=1, max_features =6 ,random_state=42, max_leaf_nodes=21, class_weight={0: 5.5, 1: 1})\n",
    "\n",
    "gb_model = AdaBoostClassifier(\n",
    "    estimator=dt,\n",
    "    n_estimators=600,   # Number of boosting stages to be used\n",
    "    learning_rate=0.1\n",
    "\n",
    ")\n",
    "\n",
    "# Step 2: Initialize the Gradient Boosting Classifier\n",
    "# gb_model = GradientBoostingClassifier(\n",
    "#     n_estimators=100,   # Number of boosting stages to be used\n",
    "#     learning_rate=0.2,  # Shrinks the contribution of each tree\n",
    "#     max_depth=1,        # Maximum depth of the individual trees\n",
    "#     random_state=42,\n",
    "#     max_features=6\n",
    "# )\n",
    "\n",
    "# Step 3: Train the Boosting model\n",
    "gb_model.fit(train_f, train_t)\n",
    "\n",
    "# Step 4: Predict on the validation set\n",
    "val_predictions = gb_model.predict(val_f)\n",
    "\n",
    "# Step 5: Calculate accuracy,precision,f1 and recall\n",
    "accuracy = accuracy_score(val_t, val_predictions)\n",
    "recall = recall_score(val_t, val_predictions)\n",
    "precision = precision_score(val_t,val_predictions)\n",
    "f1 = f1_score(val_t,val_predictions)\n",
    "\n",
    "# Output the validation accuracy and recall\n",
    "print(\"Validation accuracy:\", accuracy)\n",
    "print(\"Validation recall:\", recall)\n",
    "print(\"precision: \",precision)\n",
    "print(\"f1: \",f1)\n",
    "\n",
    "# Step 6: Impute missing values in the test data\n",
    "test_df[mean_impute_cols] = mean_imputer.transform(test_df[mean_impute_cols])\n",
    "test_df[mode_impute_cols] = mode_imputer.transform(test_df[mode_impute_cols])\n",
    "\n",
    "# Prepare the test set\n",
    "test_features = pd.DataFrame(test_df, columns=test_df.columns)\n",
    "test_features = test_features.drop(columns=['RecordId'] + dropped_columns)\n",
    "#test_features = scaler.transform(test_features)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "test_pred = gb_model.predict_proba(test_features)[:, 1]\n",
    "\n",
    "# Step 8: Create the submission DataFrame\n",
    "kaggle_submission = pd.DataFrame({'RecordId': test_df['RecordId'].astype(int), 'Y': test_pred})\n",
    "\n",
    "# Step 9: Save the submission file\n",
    "kaggle_submission.to_csv('ada2_boosting_submission.csv', index=False)\n",
    "\n",
    "print('Submission file created successfully.')\n",
    "\n",
    "# Validation accuracy: 0.997494481086718\n",
    "# Validation recall: 0.09836065573770492\n",
    "# precision 0.47368421052631576\n",
    "# Submission file created successfully.\n",
    "\n",
    "# Validation accuracy: 0.9973319609409916\n",
    "# Validation recall: 0.11475409836065574\n",
    "# precision 0.375\n",
    "# Submission file created successfully. learning rate = 0.4\n",
    "\n",
    "# Validation accuracy: 0.9975486544686268\n",
    "# Validation recall: 0.10382513661202186\n",
    "# precision 0.5277777777777778\n",
    "# Submission file created successfully.     n_estimators=100,   # Number of boosting stages to be used\n",
    "    # learning_rate=0.4,  # Shrinks the contribution of each tree\n",
    "    # max_depth=1,        # Maximum depth of the individual trees\n",
    "    # random_state=42,\n",
    "    # max_features=6\n",
    "\n",
    "\n",
    "\n",
    "# Validation accuracy: 0.9976299145414901\n",
    "# Validation recall: 0.1092896174863388\n",
    "# precision 0.625\n",
    "# Submission file created successfully.\n",
    "# gb_model = GradientBoostingClassifier(\n",
    "    # n_estimators=100,   # Number of boosting stages to be used\n",
    "    # learning_rate=0.2,  # Shrinks the contribution of each tree\n",
    "    # max_depth=1,        # Maximum depth of the individual trees\n",
    "    # random_state=42,\n",
    "    # max_features=6\n",
    "# )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also tried DTs and Random forest, over there the optimal depth was 15 and optimal max features were 8, then again increasing the estimators increased the accuracy, greater than 15 depth and greater than max features used to decrease the accuracy and over fit. Lesser than 8 features used and less than 8 depth used to underfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then tried bagging with rf and it worked pretty well when i set the class weight to balanced, setting the class weight to balanced meant that we were focusing on predicting the 1s accuractely, rf is used usually on imbalance data sets and over here using it with bagging increased my rf accuracy from 91% to bagging with rf 93.8 %\n",
    "\n",
    "Increasing estimators increased the overall accuracy, max features were set at 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
